{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/prashantkarna/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from tabulate import tabulate\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn import metrics\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "nltk.download('vader_lexicon')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from tensorflow.keras.models import load_model\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tqdm import tqdm\n",
    "import neattext.functions as nfx\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding,Dense,LSTM,Bidirectional,GlobalMaxPooling1D,Input,Dropout\n",
    "import pickle\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data = pd.read_csv('/Users/prashantkarna/Documents/Research Materials/Datasets/Suicide_Detection.csv')\n",
    "\n",
    "# data['class'] = data['class'].replace(['suicide'], 1)\n",
    "# data['class'] = data['class'].replace(['non-suicide'], 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv('/Users/prashantkarna/Documents/Research Materials/Datasets/depression_dataset_reddit_cleaned.csv')\n",
    "# rename the columns\n",
    "data = data.rename(columns={'clean_text': 'text', 'is_depression': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# data2 = pd.read_csv('/Users/prashantkarna/Documents/Research Materials/Datasets/depression_dataset_reddit_cleaned.csv')\n",
    "# # rename the columns\n",
    "# data2 = data2.rename(columns={'clean_text': 'text', 'is_depression': 'class'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.concat([data1,data2])\n",
    "# data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# data_split = np.array_split(Suicide, 3)\n",
    "# Suicide = data_split[0]\n",
    "# data = data.drop('Unnamed: 0', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7731, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1041d8580>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.catplot(x=\"class\", kind=\"count\",  data= data)\n",
    "# plt.savefig('type.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>232074.0</td>\n",
       "      <td>174152.863518</td>\n",
       "      <td>100500.425362</td>\n",
       "      <td>2.0</td>\n",
       "      <td>87049.25</td>\n",
       "      <td>174358.5</td>\n",
       "      <td>261285.75</td>\n",
       "      <td>348110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>232074.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500001</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.5</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               count           mean            std  min       25%       50%  \\\n",
       "Unnamed: 0  232074.0  174152.863518  100500.425362  2.0  87049.25  174358.5   \n",
       "class       232074.0       0.500000       0.500001  0.0      0.00       0.5   \n",
       "\n",
       "                  75%       max  \n",
       "Unnamed: 0  261285.75  348110.0  \n",
       "class            1.00       1.0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "class         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>class</th>\n",
       "      <td>0.000739</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Unnamed: 0     class\n",
       "Unnamed: 0    1.000000  0.000739\n",
       "class         0.000739  1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_corr = data.corr()\n",
    "data_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = [36, 27])\n",
    "\n",
    "# sns.heatmap(data.corr(), cmap = 'RdYlGn', annot = True, vmax = 0.7, vmin = -0.7);\n",
    "# plt.title('Pair-wise correlation coefficients across attributes');\n",
    "\n",
    "# # plt.savefig('cor_all.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/prashantkarna/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('class', axis=1)\n",
    "y = data['class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_arr = pd.Series(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,5))\n",
    "plt.pie(y_arr.value_counts(),startangle=90,colors=['#00dddf','#000fbb'],\n",
    "       autopct='%0.2f%%',labels=['1','0'])\n",
    "plt.title('DEPRESSED OR NOT_DEPRESSED ?',fontdict={'size':20})\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To remove emails\n",
    "email_regex = r'([a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+)'\n",
    "regexes_to_remove = [email_regex, r'Subject:', r'Re:']\n",
    "\n",
    "for i in range(0, len(X)):\n",
    "    # removing all special charachter\n",
    "    review = re.sub('[^a-zA-Z]', ' ', str(X['text'][i]))\n",
    "    # make document as lowerCase\n",
    "    review = review.lower()\n",
    "    # splitting the documents into words for ex ['iam', 'omar']\n",
    "    review = review.split()\n",
    "    # make lemmatization --> (change, changing, changes)---> (change)\n",
    "    review = [lemmatizer.lemmatize(word) for word in review if not word in set(stopwords)]\n",
    "    # join the document agian\n",
    "    review = ' '.join(review)\n",
    "    \n",
    "    # removing mails\n",
    "    for r in regexes_to_remove:\n",
    "        X['text'][i] = re.sub(r, '', review)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer=Tokenizer()\n",
    "# tokenizer.fit_on_texts(X['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_freq=pd.DataFrame(tokenizer.word_counts.items(),columns=['word','count']).sort_values(by='count',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10,10))\n",
    "# sns.barplot(x='count',y='word',data=word_freq.iloc[:50])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature_names=word_freq['word'].values\n",
    "# wc=WordCloud(max_words=400)\n",
    "# wc.generate(' '.join(word for word in feature_names[500:3500] ))\n",
    "# plt.figure(figsize=(10,15))\n",
    "# plt.axis('off')\n",
    "# plt.imshow(wc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer_uni = TfidfVectorizer(max_features=10000,ngram_range=(1,1))\n",
    "tfidf_vectorizer_bi = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "tfidf_vectorizer_tri = TfidfVectorizer(max_features=10000, ngram_range=(1,3))\n",
    "\n",
    "\n",
    "X_tfidf_uni = tfidf_vectorizer_uni.fit_transform(X['text'])\n",
    "# X_tfidf_test_uni = tfidf_vectorizer_uni.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_bi = tfidf_vectorizer_bi.fit_transform(X['text'])\n",
    "# X_tfidf_test_bi =tfidf_vectorizer_bi.transform(X_test['text'])\n",
    "\n",
    "X_tfidf_tri = tfidf_vectorizer_tri.fit_transform(X['text'])\n",
    "# X_tfidf_test_tri = tfidf_vectorizer_tri.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vectorizer = TfidfVectorizer(max_features=10000)\n",
    "# tfidf_vectorizer_n12 = TfidfVectorizer(max_features=10000, ngram_range=(1,2))\n",
    "\n",
    "\n",
    "# X_tfidf_train = tfidf_vectorizer.fit_transform(X_train['text'])\n",
    "# X_tfidf_test = tfidf_vectorizer.transform(X_test['text'])\n",
    "\n",
    "# X_tfidf_train_n12= tfidf_vectorizer_n12.fit_transform(X_train['text'])\n",
    "# X_tfidf_test_n12=tfidf_vectorizer_n12.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorizer = CountVectorizer()\n",
    "  \n",
    "# X_bow_train = vectorizer.fit_transform(X_train['text'])\n",
    "# X_bow_test = vectorizer.transform(X_test['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "# def get_vader_scores(data):\n",
    "#     sid=SIA()\n",
    "#     vader_df=data.copy()\n",
    "#     vader_df['scores'] = vader_df['text'].apply(lambda txt: sid.polarity_scores(str(txt)))\n",
    "    \n",
    "#     vader_df['neg_score'] = vader_df['scores'].apply(lambda txt: txt['neg'])\n",
    "#     vader_df['neu_score'] =vader_df['scores'].apply(lambda txt: txt['neu'])\n",
    "#     vader_df['pos_score'] = vader_df['scores'].apply(lambda txt: txt['pos'])\n",
    "#     vader_df['compound'] = vader_df['scores'].apply(lambda txt: txt['compound'])\n",
    "#     vader_df.drop('scores', axis=1, inplace=True)\n",
    "#     vader_df.drop('text', axis=1, inplace=True)\n",
    "#     return vader_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_vader_train = get_vader_scores(X_train)\n",
    "# X_vader_test= get_vader_scores(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.svm import LinearSVC\n",
    "# from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# # We Can select any model but linearSVC has l1 norm penality which deals with sparse\n",
    "# lsvc = LinearSVC(C=100, penalty='l1', max_iter=500, dual=False)\n",
    "# lsvc.fit(X_tfidf_train, y_train)\n",
    "\n",
    "# # This function select the best features that has high weigh\n",
    "# fs = SelectFromModel(lsvc, prefit=True)\n",
    "# # This function redeuce X to the selected features\n",
    "# X_selection = fs.transform(X_tfidf_train)\n",
    "# X_test_selection = fs.transform(X_tfidf_test)\n",
    "\n",
    "\n",
    "# lsvc.fit(X_tfidf_train_n12, y_train)\n",
    "# fs_n12 = SelectFromModel(lsvc, prefit=True)\n",
    "# X_selection_n12 = fs_n12.transform(X_tfidf_train_n12)\n",
    "# X_test_selection_n12 = fs_n12.transform(X_tfidf_test_n12)\n",
    "\n",
    "# lsvc.fit(X_bow_train, y_train)\n",
    "# fs_n12 = SelectFromModel(lsvc, prefit=True)\n",
    "# X_selection_bow = fs_n12.transform(X_bow_train)\n",
    "# X_test_selection_bow = fs_n12.transform(X_bow_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsvc = LinearSVC(C=1000, penalty='l1', max_iter=500, dual=False)\n",
    "# lsvc.fit(X_selection, y_train)\n",
    "# y_predict_tfidf = lsvc.predict(X_test_selection)\n",
    "\n",
    "# lsvc.fit(X_selection_n12,y_train)\n",
    "# y_predict_tfidf_n12 = lsvc.predict(X_test_selection_n12)\n",
    "\n",
    "# lsvc.fit(X_selection_bow,y_train)\n",
    "# y_predict_bow = lsvc.predict(X_test_selection_bow)\n",
    "\n",
    "# lsvc.fit(X_vader_train,y_train)\n",
    "# y_predict_vader = lsvc.predict(X_vader_test)\n",
    "\n",
    "# linear_svm_tfidf_results=metrics.precision_recall_fscore_support(y_test, y_predict_tfidf)\n",
    "# linear_svm_tfidf_n12_results=metrics.precision_recall_fscore_support(y_test, y_predict_tfidf_n12)\n",
    "# linear_svm_bow_results=metrics.precision_recall_fscore_support(y_test, y_predict_bow)\n",
    "# vader_svm_results=metrics.precision_recall_fscore_support(y_test, y_predict_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_acc= metrics.accuracy_score(y_test, y_predict_tfidf)\n",
    "# tfidf_n12_acc=accuracy_score(y_test, y_predict_tfidf_n12)\n",
    "# bow_acc= accuracy_score(y_test, y_predict_bow)\n",
    "# vader_acc=accuracy_score(y_test, y_predict_vader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data1 = [['TF-IDF','TF-IDF 2-grams ','bag of words','vader'],\n",
    "#          ['precision',linear_svm_tfidf_results[0][0],linear_svm_tfidf_n12_results[0][0],linear_svm_bow_results[0][0],\n",
    "#           vader_svm_results[0][0]],\n",
    "#          ['recall',linear_svm_tfidf_results[1][0],linear_svm_tfidf_n12_results[1][0],linear_svm_bow_results[1][0],\n",
    "#           vader_svm_results[1][0]],\n",
    "#          ['F1-score',linear_svm_tfidf_results[2][0],linear_svm_tfidf_n12_results[2][0],linear_svm_bow_results[2][0],\n",
    "#           vader_svm_results[2][0]],\n",
    "#         ['accuracy',tfidf_acc,tfidf_n12_acc,bow_acc,\n",
    "#           vader_acc]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(tabulate(data1,headers='firstrow',tablefmt='fancy_grid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       780\n",
      "           1       0.98      0.96      0.97       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.97      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       780\n",
      "           1       0.98      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86       780\n",
      "           1       0.80      0.98      0.88       766\n",
      "\n",
      "    accuracy                           0.87      1546\n",
      "   macro avg       0.89      0.87      0.87      1546\n",
      "weighted avg       0.89      0.87      0.87      1546\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       780\n",
      "           1       0.99      0.93      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "XGBoost Classifier bi classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       780\n",
      "           1       0.99      0.95      0.97       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.97      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "LinearSVC best accuracy: 0.9689521345407504\n",
      "Logistic Regression best accuracy: 0.9592496765847348\n",
      "Naive Bayes best accuracy: 0.871927554980595\n",
      "Random Forest Accuracy: 0.96248382923674\n",
      "XGBoost best accuracy: 0.9683053040103493\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Set up Stratified KFold\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "svm = LinearSVC()\n",
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB(alpha=0.01)\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define lists to store accuracy scores\n",
    "svm_acc = []\n",
    "lr_acc = []\n",
    "nb_acc = []\n",
    "rf_acc=[]\n",
    "xgb_acc=[]\n",
    "\n",
    "# Perform stratified k-fold cross-validation on selected features\n",
    "for train_index, test_index in skf.split(X_tfidf_bi , y):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test = X_tfidf_bi [train_index], X_tfidf_bi [test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    " # Fit and predict using LinearSVC\n",
    "svm.fit(X_train, y_train)\n",
    "svm_pred = svm.predict(X_test)\n",
    "svm_acc.append(accuracy_score(y_test, svm_pred))\n",
    "print(\"LinearSVC classification report:\\n\", classification_report(y_test, svm_pred))\n",
    "    \n",
    " # Fit and predict using Logistic Regression\n",
    "lr.fit(X_train, y_train)\n",
    "lr_pred = lr.predict(X_test)\n",
    "lr_acc.append(accuracy_score(y_test, lr_pred))\n",
    "print(\"Logistic Regression classification report:\\n\", classification_report(y_test, lr_pred))\n",
    "    \n",
    "# Fit and predict using Naive Bayes\n",
    "nb.fit(X_train, y_train)\n",
    "nb_pred = nb.predict(X_test)\n",
    "nb_acc.append(accuracy_score(y_test, nb_pred))\n",
    "print(\"Naive Bayes classification report:\\n\", classification_report(y_test, nb_pred))\n",
    "\n",
    "# Fit and predict using Random Forest Classifier\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict(X_test)\n",
    "\n",
    "# Calculate accuracy and print classification report\n",
    "rf_acc = accuracy_score(y_test, rf_pred)\n",
    "\n",
    "print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "# Fit and predict using XGBoost Classifier\n",
    "xgb.fit(X_train, y_train, eval_metric='error')\n",
    "xgb_pred = xgb.predict(X_test)\n",
    "xgb_acc.append(accuracy_score(y_test, xgb_pred))\n",
    "\n",
    "# Print classification report\n",
    "print(\"XGBoost Classifier bi classification report:\\n\", classification_report(y_test, xgb_pred))\n",
    "\n",
    "\n",
    "\n",
    "# Print best accuracy score for each classifier\n",
    "print(\"LinearSVC best accuracy:\", np.mean(svm_acc))\n",
    "print(\"Logistic Regression best accuracy:\", np.mean(lr_acc))\n",
    "print(\"Naive Bayes best accuracy:\", np.mean(nb_acc))\n",
    "print(\"Random Forest Accuracy:\", np.mean(rf_acc))\n",
    "print(\"XGBoost best accuracy:\", np.mean(xgb_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       780\n",
      "           1       0.98      0.92      0.95       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.95      0.95      0.95      1547\n",
      "weighted avg       0.95      0.95      0.95      1547\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       780\n",
      "           1       0.98      0.92      0.95       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.96      0.95      0.95      1547\n",
      "weighted avg       0.96      0.95      0.95      1547\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.86      0.91       780\n",
      "           1       0.87      0.97      0.92       767\n",
      "\n",
      "    accuracy                           0.91      1547\n",
      "   macro avg       0.92      0.92      0.91      1547\n",
      "weighted avg       0.92      0.91      0.91      1547\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.99      0.95       780\n",
      "           1       0.99      0.90      0.95       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.95      0.95      0.95      1547\n",
      "weighted avg       0.95      0.95      0.95      1547\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       780\n",
      "           1       0.98      0.93      0.95       767\n",
      "\n",
      "    accuracy                           0.96      1547\n",
      "   macro avg       0.96      0.96      0.96      1547\n",
      "weighted avg       0.96      0.96      0.96      1547\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.97      0.96       780\n",
      "           1       0.97      0.95      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       780\n",
      "           1       0.98      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91       780\n",
      "           1       0.86      0.98      0.92       766\n",
      "\n",
      "    accuracy                           0.91      1546\n",
      "   macro avg       0.92      0.91      0.91      1546\n",
      "weighted avg       0.92      0.91      0.91      1546\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       780\n",
      "           1       0.99      0.92      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       780\n",
      "           1       0.98      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       780\n",
      "           1       0.98      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.95       780\n",
      "           1       0.97      0.92      0.94       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89       780\n",
      "           1       0.85      0.97      0.91       766\n",
      "\n",
      "    accuracy                           0.90      1546\n",
      "   macro avg       0.91      0.90      0.90      1546\n",
      "weighted avg       0.91      0.90      0.90      1546\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       780\n",
      "           1       0.99      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.96      0.95      0.95      1546\n",
      "weighted avg       0.96      0.95      0.95      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       780\n",
      "           1       0.98      0.93      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       780\n",
      "           1       0.97      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       780\n",
      "           1       0.97      0.91      0.94       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.94      0.94      1546\n",
      "weighted avg       0.95      0.95      0.94      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89       780\n",
      "           1       0.85      0.96      0.90       766\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.90      0.89      0.89      1546\n",
      "weighted avg       0.90      0.89      0.89      1546\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       780\n",
      "           1       0.99      0.91      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.96      0.95      0.95      1546\n",
      "weighted avg       0.96      0.95      0.95      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.98      0.96       780\n",
      "           1       0.98      0.93      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.98      0.97       780\n",
      "           1       0.98      0.96      0.97       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.97      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       780\n",
      "           1       0.98      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.83      0.90       780\n",
      "           1       0.85      0.98      0.91       766\n",
      "\n",
      "    accuracy                           0.90      1546\n",
      "   macro avg       0.91      0.90      0.90      1546\n",
      "weighted avg       0.91      0.90      0.90      1546\n",
      "\n",
      "Random Forest Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       780\n",
      "           1       0.99      0.93      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.97      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       780\n",
      "           1       0.99      0.95      0.97       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.97      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "LinearSVC best accuracy: 0.9573153731589163\n",
      "Logistic Regression best accuracy: 0.9512349989254334\n",
      "Naive Bayes best accuracy: 0.9049269503801123\n",
      "Random Forest Accuracy: 0.963130659767141\n",
      "XGBoost Classifier best accuracy: 0.9588673483125959\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Set up Stratified KFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "svm = LinearSVC()\n",
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define lists to store accuracy scores\n",
    "svm_acc = []\n",
    "lr_acc = []\n",
    "nb_acc = []\n",
    "rf_acc = []\n",
    "xgb_acc = []\n",
    "\n",
    "# Perform stratified k-fold cross-validation on selected features\n",
    "for train_index, test_index in skf.split(X_tfidf_tri , y):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test = X_tfidf_tri [train_index], X_tfidf_tri [test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit and predict using LinearSVC\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_acc.append(accuracy_score(y_test, svm_pred))\n",
    "    print(\"LinearSVC classification report:\\n\", classification_report(y_test, svm_pred))\n",
    "    \n",
    "    # Fit and predict using Logistic Regression\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    lr_acc.append(accuracy_score(y_test, lr_pred))\n",
    "    print(\"Logistic Regression classification report:\\n\", classification_report(y_test, lr_pred))\n",
    "    \n",
    "    # Fit and predict using Naive Bayes\n",
    "    nb.fit(X_train, y_train)\n",
    "    nb_pred = nb.predict(X_test)\n",
    "    nb_acc.append(accuracy_score(y_test, nb_pred))\n",
    "    print(\"Naive Bayes classification report:\\n\", classification_report(y_test, nb_pred))\n",
    "\n",
    "    # Fit and predict using Random Forest Classifier\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "\n",
    "    # Calculate accuracy and print classification report\n",
    "    rf_acc = accuracy_score(y_test, rf_pred)\n",
    "   \n",
    "    print(\"Random Forest Classification Report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "    # Fit and predict using XGBoost Classifier\n",
    "    xgb.fit(X_train, y_train, eval_metric='error')\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_acc.append(accuracy_score(y_test, xgb_pred))\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"XGBoost Classifier classification report:\\n\", classification_report(y_test, xgb_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print best accuracy score for each classifier\n",
    "print(\"LinearSVC best accuracy:\", np.mean(svm_acc))\n",
    "print(\"Logistic Regression best accuracy:\", np.mean(lr_acc))\n",
    "print(\"Naive Bayes best accuracy:\", np.mean(nb_acc))\n",
    "print(\"Random Forest Accuracy:\", np.mean(rf_acc))\n",
    "print(\"XGBoost Classifier best accuracy:\", np.mean(xgb_acc))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       780\n",
      "           1       0.97      0.92      0.95       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.95      0.95      0.95      1547\n",
      "weighted avg       0.95      0.95      0.95      1547\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       780\n",
      "           1       0.98      0.91      0.94       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.95      0.95      0.95      1547\n",
      "weighted avg       0.95      0.95      0.95      1547\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.80      0.88       780\n",
      "           1       0.82      0.98      0.89       767\n",
      "\n",
      "    accuracy                           0.89      1547\n",
      "   macro avg       0.90      0.89      0.88      1547\n",
      "weighted avg       0.90      0.89      0.88      1547\n",
      "\n",
      "Random Forest classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96       780\n",
      "           1       1.00      0.91      0.95       767\n",
      "\n",
      "    accuracy                           0.95      1547\n",
      "   macro avg       0.96      0.95      0.95      1547\n",
      "weighted avg       0.96      0.95      0.95      1547\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       780\n",
      "           1       0.99      0.93      0.96       767\n",
      "\n",
      "    accuracy                           0.96      1547\n",
      "   macro avg       0.96      0.96      0.96      1547\n",
      "weighted avg       0.96      0.96      0.96      1547\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.96       780\n",
      "           1       0.98      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       780\n",
      "           1       0.97      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.79      0.87       780\n",
      "           1       0.82      0.98      0.90       766\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.90      0.89      0.89      1546\n",
      "weighted avg       0.90      0.89      0.89      1546\n",
      "\n",
      "Random Forest classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       780\n",
      "           1       0.99      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       780\n",
      "           1       0.98      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       780\n",
      "           1       0.98      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.96      0.95      0.95      1546\n",
      "weighted avg       0.96      0.95      0.95      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.98      0.95       780\n",
      "           1       0.98      0.91      0.94       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.80      0.88       780\n",
      "           1       0.83      0.98      0.90       766\n",
      "\n",
      "    accuracy                           0.89      1546\n",
      "   macro avg       0.90      0.89      0.89      1546\n",
      "weighted avg       0.90      0.89      0.89      1546\n",
      "\n",
      "Random Forest classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.99      0.96       780\n",
      "           1       0.99      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       780\n",
      "           1       0.98      0.92      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.97      0.96       780\n",
      "           1       0.97      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.97      0.94       780\n",
      "           1       0.97      0.91      0.94       766\n",
      "\n",
      "    accuracy                           0.94      1546\n",
      "   macro avg       0.94      0.94      0.94      1546\n",
      "weighted avg       0.94      0.94      0.94      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.79      0.87       780\n",
      "           1       0.82      0.98      0.89       766\n",
      "\n",
      "    accuracy                           0.88      1546\n",
      "   macro avg       0.90      0.88      0.88      1546\n",
      "weighted avg       0.90      0.88      0.88      1546\n",
      "\n",
      "Random Forest classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.99      0.96       780\n",
      "           1       0.99      0.91      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.96      0.95      0.95      1546\n",
      "weighted avg       0.96      0.95      0.95      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95       780\n",
      "           1       0.98      0.93      0.95       766\n",
      "\n",
      "    accuracy                           0.95      1546\n",
      "   macro avg       0.95      0.95      0.95      1546\n",
      "weighted avg       0.95      0.95      0.95      1546\n",
      "\n",
      "LinearSVC classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       780\n",
      "           1       0.98      0.94      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Logistic Regression classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.96       780\n",
      "           1       0.98      0.93      0.96       766\n",
      "\n",
      "    accuracy                           0.96      1546\n",
      "   macro avg       0.96      0.96      0.96      1546\n",
      "weighted avg       0.96      0.96      0.96      1546\n",
      "\n",
      "Naive Bayes classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.76      0.86       780\n",
      "           1       0.80      0.98      0.88       766\n",
      "\n",
      "    accuracy                           0.87      1546\n",
      "   macro avg       0.89      0.87      0.87      1546\n",
      "weighted avg       0.89      0.87      0.87      1546\n",
      "\n",
      "Random Forest classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97       780\n",
      "           1       1.00      0.94      0.97       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.97      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "XGBoost Classifier classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.98      0.97       780\n",
      "           1       0.98      0.95      0.96       766\n",
      "\n",
      "    accuracy                           0.97      1546\n",
      "   macro avg       0.97      0.96      0.97      1546\n",
      "weighted avg       0.97      0.97      0.97      1546\n",
      "\n",
      "LinearSVC best accuracy: 0.9562809460534138\n",
      "Logistic Regression best accuracy: 0.9478724000297701\n",
      "Naive Bayes best accuracy: 0.8831972076321822\n",
      "Random Forest Accuracy: 0.9573151222873466\n",
      "XGBoost Classifier best accuracy: 0.9569264386021104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # Set up Stratified KFold\n",
    "# skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Define classifiers\n",
    "svm = LinearSVC()\n",
    "lr = LogisticRegression()\n",
    "nb = MultinomialNB()\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "# Define lists to store accuracy scores\n",
    "svm_acc = []\n",
    "lr_acc = []\n",
    "nb_acc = []\n",
    "rf_acc = []\n",
    "xgb_acc=[]\n",
    "\n",
    "# Perform stratified k-fold cross-validation on selected features\n",
    "for train_index, test_index in skf.split(X_tfidf_uni , y):\n",
    "    # Split data into training and testing sets\n",
    "    X_train, X_test = X_tfidf_uni [train_index], X_tfidf_uni [test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    # Fit and predict using LinearSVC\n",
    "    svm.fit(X_train, y_train)\n",
    "    svm_pred = svm.predict(X_test)\n",
    "    svm_acc.append(accuracy_score(y_test, svm_pred))\n",
    "    print(\"LinearSVC classification report:\\n\", classification_report(y_test, svm_pred))\n",
    "    \n",
    "    # Fit and predict using Logistic Regression\n",
    "    lr.fit(X_train, y_train)\n",
    "    lr_pred = lr.predict(X_test)\n",
    "    lr_acc.append(accuracy_score(y_test, lr_pred))\n",
    "    print(\"Logistic Regression classification report:\\n\", classification_report(y_test, lr_pred))\n",
    "    \n",
    "    # Fit and predict using Naive Bayes\n",
    "    nb.fit(X_train, y_train)\n",
    "    nb_pred = nb.predict(X_test)\n",
    "    nb_acc.append(accuracy_score(y_test, nb_pred))\n",
    "    print(\"Naive Bayes classification report:\\n\", classification_report(y_test, nb_pred))\n",
    "\n",
    "\n",
    "\n",
    "    # Fit and predict using Random Forest Classifier\n",
    "    rf.fit(X_train, y_train)\n",
    "    rf_pred = rf.predict(X_test)\n",
    "    rf_acc.append(accuracy_score(y_test, rf_pred))      \n",
    "    # Print classification report\n",
    "    print(\"Random Forest classification report:\\n\", classification_report(y_test, rf_pred))\n",
    "\n",
    "    # Fit and predict using XGBoost Classifier\n",
    "    xgb.fit(X_train, y_train, eval_metric='error')\n",
    "    xgb_pred = xgb.predict(X_test)\n",
    "    xgb_acc.append(accuracy_score(y_test, xgb_pred))\n",
    "\n",
    "    # Print classification report\n",
    "    print(\"XGBoost Classifier classification report:\\n\", classification_report(y_test, xgb_pred))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Print best accuracy score for each classifier\n",
    "print(\"LinearSVC best accuracy:\", np.mean(svm_acc))\n",
    "print(\"Logistic Regression best accuracy:\", np.mean(lr_acc))\n",
    "print(\"Naive Bayes best accuracy:\", np.mean(nb_acc))\n",
    "print(\"Random Forest Accuracy:\", np.mean(rf_acc))\n",
    "print(\"XGBoost Classifier best accuracy:\", np.mean(xgb_acc))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# # Create a figure to plot the ROC curves\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf_uni, y, test_size=0.2, random_state=42)\n",
    "# # Define the classifiers\n",
    "# classifiers = {'LinearSVC': svm, 'Logistic Regression': lr, 'Naive Bayes': nb, 'Random Forest': rf,'XGBClassifier':xgb}\n",
    "\n",
    "# # Loop through each classifier and plot its ROC curve\n",
    "# for name, clf in classifiers.items():\n",
    "#     # Fit the classifier and predict the probabilities of the positive class\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     if hasattr(clf, 'decision_function'):\n",
    "#         y_score = clf.decision_function(X_test)\n",
    "#     else:\n",
    "#         y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Compute the ROC curve and its AUC\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Plot the ROC curve and its AUC\n",
    "#     ax.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier curve\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "\n",
    "# # Set the labels and legend\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('ROC curves')\n",
    "# ax.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# # Create a figure to plot the ROC curves\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf_bi, y, test_size=0.2, random_state=42)\n",
    "# # Define the classifiers\n",
    "# classifiers = {'LinearSVC': svm, 'Logistic Regression': lr, 'Naive Bayes': nb, 'Random Forest': rf,'XGBClassifier':xgb}\n",
    "\n",
    "# # Loop through each classifier and plot its ROC curve\n",
    "# for name, clf in classifiers.items():\n",
    "#     # Fit the classifier and predict the probabilities of the positive class\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     if hasattr(clf, 'decision_function'):\n",
    "#         y_score = clf.decision_function(X_test)\n",
    "#     else:\n",
    "#         y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Compute the ROC curve and its AUC\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Plot the ROC curve and its AUC\n",
    "#     ax.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier curve\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "\n",
    "# # Set the labels and legend\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('ROC curves')\n",
    "# ax.legend()\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "# # Create a figure to plot the ROC curves\n",
    "# fig, ax = plt.subplots(figsize=(8, 8))\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_tfidf_tri, y, test_size=0.2, random_state=42)\n",
    "# # Define the classifiers\n",
    "# classifiers = {'LinearSVC': svm, 'Logistic Regression': lr, 'Naive Bayes': nb, 'Random Forest': rf,'XGBClassifier':xgb}\n",
    "\n",
    "# # Loop through each classifier and plot its ROC curve\n",
    "# for name, clf in classifiers.items():\n",
    "#     # Fit the classifier and predict the probabilities of the positive class\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     if hasattr(clf, 'decision_function'):\n",
    "#         y_score = clf.decision_function(X_test)\n",
    "#     else:\n",
    "#         y_score = clf.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "#     # Compute the ROC curve and its AUC\n",
    "#     fpr, tpr, thresholds = roc_curve(y_test, y_score)\n",
    "#     roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "#     # Plot the ROC curve and its AUC\n",
    "#     ax.plot(fpr, tpr, label=f'{name} (AUC = {roc_auc:.2f})')\n",
    "\n",
    "# # Plot the random classifier curve\n",
    "# ax.plot([0, 1], [0, 1], linestyle='--', color='grey')\n",
    "\n",
    "# # Set the labels and legend\n",
    "# ax.set_xlabel('False Positive Rate')\n",
    "# ax.set_ylabel('True Positive Rate')\n",
    "# ax.set_title('ROC curves')\n",
    "# ax.legend()\n",
    "# plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
